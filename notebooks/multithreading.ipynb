{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High-performance computing with Julia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we'll be looking at Julia's functionality for distributing work over multiple shared-memory workers (threads/cores). Julia also has two main packages for doing distributed-memory parallelism:\n",
    "\n",
    "- [Distributed.jl](https://docs.julialang.org/en/v1/stdlib/Distributed/) - this is a standard library that comes shipped with the language. \n",
    "- [MPI.jl](https://juliaparallel.org/MPI.jl/stable/) - a Julia wrapper for MPI.\n",
    "\n",
    "Additionally, Julia supports GPU programming via the [CUDA.jl](https://cuda.juliagpu.org/stable/) package. There is also ongoing work for supporting AMD, Intel, and Apple GPUs. You can read more about that [here](https://github.com/JuliaGPU/KernelAbstractions.jl)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multithreading in Julia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia comes packaged with a standard library called `Threads` for working with multiple shared-memory workers. However, before starting we need to make sure that Julia is started with more than one thread. To check how many Julia threads are currently running, call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Threads.nthreads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've just installed Julia without changing anything, this number will likely be one. There are multiple way to ensure that Julia starts with multiple threads.\n",
    "- Set the environment variable `JULIA_NUM_THREADS` to some number, for example to \"$(nproc)\" to use all the cores in your computer.\n",
    "- Start Julia with the `--threads` or `-t` option followed by the number of threads. I.e. `julia --threads 4`.\n",
    "- In VS Code, set the `\"julia.NumThreads\": NUMBER` option in `settings.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can readily check again how many threads we are running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Threads.nthreads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are threads?\n",
    "Threads are **execution units within a process** that can run simultaneously. While processes are separate, threads run in a **shared memory** space (heap).\n",
    "\n",
    "<!-- <img src=\"./imgs/what-are-threads.png\" width=500px> -->\n",
    "\n",
    "<br>\n",
    "<img src=\"../figures/stack_heap_threads.svg\" width=450px>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It is currently not (easily) possible to change the number of threads at runtime!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User threads vs default threads\n",
    "\n",
    "Technically, the Julia process is also spawning multiple threads already in \"single-threaded\" mode, like\n",
    "* a thread for unix signal listening\n",
    "* multiple OpenBLAS threads for BLAS/LAPACK operations\n",
    "* GC threads\n",
    "\n",
    "We call the threads that we can actually run computations on *user threads* or *Julia threads*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "BLAS.get_num_threads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where are my threads running?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ThreadPinning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threadinfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task-based multithreading\n",
    "\n",
    "In traditional HPC, one typically cares about threads directly. Using e.g. OpenMP, one essentially tells each thread what to do.\n",
    "\n",
    "Conceptually, Julia takes a different approach and implements **task-based** multithreading. In this paradigm, a task - e.g. a computational piece of a code - is marked for **parallel** execution on **any** of the available Julia threads. Julia's **dynamic scheduler** will automatically put the task on one of the threads and trigger the execution of the task on said thread.\n",
    "\n",
    "<br>\n",
    "<!-- <img src=\"imgs/task-based-parallelism.png\" width=768px> -->\n",
    "<img src=\"../figures/tasks_threads_cores.svg\" width=650px>\n",
    "</br>\n",
    "\n",
    "Generally speaking, the user should **think about tasks and not threads**.\n",
    "* The scheduler is controlling on which thread a task will eventually run.\n",
    "* It might even dynamically [migrate tasks](https://docs.julialang.org/en/v1/manual/multi-threading/#man-task-migration) between threads.\n",
    "\n",
    "**Advantages:**\n",
    "* high-level abstraction\n",
    "* nestability / composability (especially important for libraries)\n",
    "\n",
    "**Disadvantages:**\n",
    "* scheduling overhead\n",
    "* uncertain and potentially suboptimal task → thread assignment\n",
    "  * **can get in the way when performance engineering** because\n",
    "    * scheduler has limited information (e.g. about the system topology)\n",
    "    * profiling tools often don't know anything about tasks but monitor threads (or even CPU-cores) instead (e.g. LIKWID)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, Julia waits for commands to finish (\"**blocking**\") and runs everything sequentially.\n",
    "\n",
    "**Tasks** are a feature that allows (parts of) computations to be scheduled (suspended and resumed) in a flexible manner to implement **concurrency** and **parallelism**.\n",
    "\n",
    "* Concurrency\n",
    "    * Dealing with lots of things *in a time period* (\"multi-tasking\").\n",
    "    * Can be used on a single thread.\n",
    "* Parallelism\n",
    "    * Doing lots of things *at the same instant*.\n",
    "    * Needs multiple threads (or processes).\n",
    "\n",
    "Example (concurrency): **asynchronous I/O** like\n",
    "  * **multiple user input** (Why not already process some of the input?)\n",
    "  * **data dumping to disk** (Maybe it's possible to continue a calculation?)\n",
    " \n",
    "Example (parallelism): **multithreading, distributed computing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spawning parallel tasks: `Threads.@spawn`\n",
    "`Threads.@spawn` spawns a task to be run on any Julia thread. Specifically, it creates a `Task` and schedules it for execution on an available Julia thread (we don't control which one!).\n",
    "\n",
    "Note that `Threads.@spawn` is **asynchronous** and **non-blocking**, that is, it doesn't wait for the task to actually run but immediately returns a `Task`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Base.Threads # afterwards we can just write @spawn instead of Threads.@spawn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@spawn 3+3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fetch the result of a task with `fetch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = @spawn 3+3\n",
    "fetch(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While `@spawn` returns right away, `fetch` is **blocking** as it has to wait for the task to actually finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time t = @spawn begin\n",
    "    sleep(3)\n",
    "    return 3+3\n",
    "end\n",
    "@time fetch(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the macro `@sync` to synchronize all encompassed asynchronous operations (`@spawn`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time @sync t = @spawn begin\n",
    "    sleep(3)\n",
    "    return 3+3\n",
    "end\n",
    "@time fetch(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: multithreaded `map`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tmap`: *threaded map*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function tmap(fn, itr)\n",
    "    tasks = map(i -> @spawn(fn(i)), itr)  # for each i ∈ itr, spawn a task to compute fn(i)\n",
    "    return fetch.(tasks)                  # fetch and return all the results\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = [rand(200,200) for i in 1:8];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmap(svdvals, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime tmap($svdvals, $M) samples=10 evals=3;\n",
    "@btime map($svdvals, $M) samples=10 evals=3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**performance issue**:\n",
    "\n",
    "* Using Julia multithreading + BLAS multithreading\n",
    "    - CPU cores may be *overscribed*, e.g. 256 total threads on 128 CPU cores! (red bars in `htop`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you use BLAS, it is important to carefully consider and configure the [interplay between Julia threads and BLAS threads](https://carstenbauer.github.io/ThreadPinning.jl/stable/explanations/blas/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLAS.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime tmap($svdvals, $M) samples=10 evals=3;\n",
    "@btime map($svdvals, $M) samples=10 evals=3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: multithreading for-loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ThreadPinning.Utility: taskid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@sync for i in 1:2*nthreads()\n",
    "    @spawn println(\"Task \", taskid(), \" is running iteration \", i, \" on thread \", threadid())\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `@threads`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Splits up the iteration space into `nthreads()` contiguous chunks**\n",
    "* Creates a task for each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates nthreads() many tasks\n",
    "\n",
    "@threads for i in 1:2*nthreads()\n",
    "    println(\"Task \", taskid(), \" is running iteration \", i, \" on thread \", threadid())\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nestability / Composability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Recursive Fibonacci series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ F(n) = F(n-1) + F(n-2), \\qquad F(1) = F(2) = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can nest `@spawn` calls freely!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function fib(n)\n",
    "    n < 2 && return n\n",
    "    t = @spawn fib(n-2)\n",
    "    return fib(n-1) + fetch(t)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fib(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note: Algorithmically, this is a highly inefficient implementation of the Fibonacci series, of course!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multithreading: Things to be aware of"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructive example: parallel summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rand(1_000_000 * Threads.nthreads());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function sum_threads_naive(data)\n",
    "    s = zero(eltype(data))\n",
    "    @threads for x in eachindex(data)\n",
    "        s += x\n",
    "    end\n",
    "    return s\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show sum(data);\n",
    "@show sum_threads_naive(data);\n",
    "@show sum_threads_naive(data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wrong** result! Even worse, it's **non-deterministic** and different every time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a [race condition](https://en.wikipedia.org/wiki/Race_condition) which typically appear when multiple tasks are modifying a shared value simultaneously.\n",
    "\n",
    "→ **Don't modify shared \"global\" state!**\n",
    "\n",
    "Sometimes things can be more subtle. Examples: random number generation, `Dict`. Note that not all of Julia and its packages in the ecosystem are thread-safe! In general, it is safer to assume that they're not unless documented/proven otherwise. (`rand()` is thread-safe, `Dict` isn't!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools for multi-threading\n",
    "\n",
    "* [OhMyThreads.jl](https://github.com/JuliaFolds2/OhMyThreads.jl): Simple tools for basic multithreading.\n",
    "* [ThreadsX.jl](https://github.com/JuliaFolds2/ThreadsX.jl): Parallelized Base functions\n",
    "* [Tullio.jl](https://github.com/mcabbott/Tullio.jl): Tullio is a very flexible einsum macro ([Einstein notation](https://en.wikipedia.org/wiki/Einstein_notation))\n",
    "* [(LoopVectorization.jl)](https://github.com/JuliaSIMD/LoopVectorization.jl): Macro(s) for vectorizing loops.\n",
    "* [(FLoops.jl)](https://github.com/JuliaFolds/FLoops.jl): Fast sequential, threaded, and distributed for-loops for Julia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-do the exercise `Counting nucleotides` from the `1-basics.ipynb` notebook by implementing a multithreaded version. Compare the performance with the single-threaded version. Try generating your own strings with different lengths and compare the results. \n",
    "\n",
    "_Hint: You can generate `N` random elements selected from a collection by calling `rand(collection, N)`._"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.3",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
