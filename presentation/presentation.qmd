---
title: "Introduction to Julia workshop"
# subtitle: "How I Learned To Stop Worrying and Love Programming."
format: 
    julia-revealjs:
        slide-number: true
        logo: figures/api_logo_big_black.png
        footer: API January 2025
        transition: none
jupyter: julia-1.11
execute: 
  cache: true
---

# The Julia programming language

![](figures/Julia_(programming_language)_logo.png){width=5%  fig-align="center"}

## In a nutshell
A dynamic, general-purpose programming language designed to be both accessible and fast.

## In a nutshell

::: {.fragment .fade-in-then-semi-out}
- Born at MIT in 2009, first release in 2011.
    - Jeff Bezanson, Stefan Karpinski, Viral B. Shah, Alan Edelman
:::

::: {.fragment .fade-in-then-semi-out}
- Idea: A technical language that is both fast, and easy to develop.
:::

::: {.fragment .fade-in-then-semi-out}
- Version 1.0 released in 2018
:::

::: {.fragment .fade-in-then-semi-out}
- Still very actively developed, current version ~~v1.10.5~~ v1.11
:::


## Core features

::: {.fragment .fade-in-then-semi-out}
- Inherently fast and easy to optimize 
:::

::: {.fragment .fade-in-then-semi-out}
- Built-in package manager and general registry
:::

::: {.fragment .fade-in-then-semi-out}
- Virtual environments
:::

::: {.fragment .fade-in-then-semi-out}
- Intuitive and math-like syntax
:::

::: {.fragment .fade-in-then-semi-out}
- Composable: seperate parts work together
:::

::: {.fragment .fade-in-then-semi-out}
- Free and open source
:::

## Other features

:::: {.columns}

::: {.column width="45%"}
- Easy parallelism (including GPU)
- GPU accelerated plotting
- Call C and Fortran functions natively
- Easy to call Python code
- Automatic differentiation
:::

::: {.column width="45%"}
- Automically generate efficient, specialized code
- Metaprogramming - code that returns code
- Unicode support
- Automated memory management
:::

::::

# Julia lets you do prototyping, deployment, and analysis all in one.

# Julia's performance

## Microbenchmarks

![](figures/benchmarks.jpeg){fig-align="center"}

## Other benchmarks {.scrollable}
::: {.incremental}
- DataFrames.jl vs. pandas
    - Consistently 10x, 20x, up to 100x faster on various tasks ([Database-like ops benchmark](https://duckdblabs.github.io/db-benchmark/))
- DifferentialEquations.jl
    - Outperforms Matlab, SciPy, Sundials, deSolve ![](figures/diffeq_benchmarks.png)
        - [The SciML Benchmarks](https://docs.sciml.ai/SciMLBenchmarksOutput/stable/MultiLanguage/ode_wrapper_packages/#ODE-Solver-Multi-Language-Wrapper-Package-Work-Precision-Benchmarks-(MATLAB,-SciPy,-Julia,-deSolve-(R)))
:::

## Consequence {.smaller}

- Easy to write your own code that is fast and accessible. 
- Packages do not need to rely on interfacing into languages like C and Fortran.
- No black box of mixed languages.
    - Julia all the way down

![](figures/alwayshasbeen.png){fig-align="center"}

## Examples

::: {.incremental}
- Numpy: ![](figures/numpy.png){width=50%}
- Scipy: ![](figures/scipy.png){width=50%}
- Astropy: ![](figures/astropy.png){width=50%}
- OrdinaryDiffEq.jl, Turing.jl, Syzygy.jl, Optimization.jl ![](figures/diffeq-turing-syzygy.png){width=50% fig-align="center"}
:::

## How is Julia

::: {.fragment .fade-in-then-semi-out}
- Julia is a JIT (**J**ust **I**n **T**ime)-compiled language
:::

::: {.fragment .fade-in-then-semi-out}
- Dynamically typed, with option to declare types
:::

::: {.fragment .fade-in-then-semi-out}
- Interactive
:::


## What does Julia look like?

##
```{julia}
#| echo: true
using LinearAlgebra
using Unitful: Unitful, Mass, Length, Velocity, @u_str
using Unitful.DefaultSymbols: kg, m, s, km, J
using UnitfulAstro

const G = 6.674e-11m^3/kg/s^2

struct Star{L <: Length, V <: Velocity}
    mass::Mass
    position::Vector{L}
    velocity::Vector{V}
end

kinetic_energy(s::Star) = s.mass*(s.velocity ⋅ s.velocity)/2

function potential_energy(star1::Star, star2::Star)
    m₁ = star1.mass
    m₂ = star2.mass
    r = norm(star1.position - star2.position)
    return -G*m₁*m₂/r
end;
```

##

```{.julia code-line-numbers="1-4|6|8-12|14|16-21"}
using LinearAlgebra
using Unitful: Unitful, Mass, Length, Velocity, @u_str
using Unitful.DefaultSymbols: kg, m, s, km, J
using UnitfulAstro

const G = 6.674e-11m^3/kg/s^2

struct Star{L <: Length, V <: Velocity}
    mass::Mass
    position::Vector{L}
    velocity::Vector{V}
end

kinetic_energy(s::Star) = s.mass*(s.velocity ⋅ s.velocity)/2

function potential_energy(star1::Star, star2::Star)
    m₁ = star1.mass
    m₂ = star2.mass
    r = norm(star1.position - star2.position)
    return -G*m₁*m₂/r
end
```

##

```{julia}
#| echo: true
#| code-line-numbers: "3-9|11|12|14-18"
#| output-location: fragment

erg = u"erg"

star1 = Star(1.0u"Msun",
             [1.0,  0.0]u"Rsun", 
             [0.0, -5.0]u"km/s")
             
star2 = Star(2.0u"Msun", 
             [-0.5, 0.0]u"Rsun", 
             [ 0.0, 3.0]u"km/s")

T = kinetic_energy(star1)
U = potential_energy(star1, star2)

@show T
@show U

@show erg(T)
@show erg(U);
```   

# Multiple dispatch

## A simple example

```{julia}
#| echo: true
#| output-location: fragment

struct Dog end
struct Cat end

speak(d::Dog) = println("Woof!")
speak(c::Cat) = println("Meow!")

animals = [Dog(), Cat()]

for animal in animals
    speak(animal)
end
```

## A better example

```{julia}
#| echo: true
#| code-line-numbers: "1|3|5|7|9|11|13"
#| output-location: fragment

using Measurements, OrdinaryDiffEqTsit5

f(u, p, t) = p[1]*u

u0 = 0.5 ± 0.0

tspan = (0.0 ± 0.0, 1.0 ± 0.0)

p = [1.01 ± 0.01]

prob = ODEProblem(f, u0, tspan, p)

sol = solve(prob, Tsit5(), reltol=1e-8, abstol=1e-8)
```



# What's bad about Julia?

## What's bad about Julia? {.smaller}

:::: {.columns}

::: {.incremental .column width="60%"}
- Startup latency
    - Time To First X (TTFX)
        - Getting better every year
- Easy to learn, hard to master (like baking bread!)
    - Many new concepts, eg. multiple dispatch, metaprogramming
- ~~No small binaries~~
    - This is now possible.
:::

::: {.column width="40%"}
![](figures/ttfdx.png)
:::

::::

## Okay I'm intriged...

... but I don't want to re-write all my spaghetti code!!

. . .

Fair point! But a few things to note:

::: {.incremental}
- Julia gets you 90% of the way with 10% of the effort
- You can easily call Python code in Julia
    - So start with all Python and gradually swap out parts
:::

# Thank you!

Questions?

## Resources

- [The offical Julia website](https://julialang.org/)
- [Astronomy packages for Julia](https://juliaastro.org/dev/index.html)
- [Julia workflows: best practices](https://modernjuliaworkflows.org/)
- [The official Julia documentation](https://docs.julialang.org/en/v1/)
- [The Julia discourse](discourse.julialang.org)
- [The Julia slack](julialang.slack.com)
- [CUDA in Julia](https://cuda.juliagpu.org/stable/)
- [Julia on HPC](https://github.com/JuliaParallel/JUHPC)

# Extra slides

## CUDA

```{.julia}
using CUDA

N = 1e6
A = CUDA.fill(1.0f0, N)
B = CUDA.fill(1.0f0, N)

C = A .+ B
```

## Stellar evolution

```{.julia}
abstract type StellarType
struct MainSequence <: StellarType end
struct RedGiant     <: StellarType end

struct Star{T, tT <: StellarType}
    M::T
    L::T
    R::T
    stellar_type::tT
end
    

function stellar_winds(star::Star{T, tT}) where tT <: MainSequence
    return a_wind_prescription(star.M)
end

function stellar_winds(star::Star{T, tT}) where tT <: RedGiant
    return a_different_wind_prescription(star.M, star.L)
end
```

## N-body collision

```{.julia}
abstract type StellarType
struct MainSequence <: StellarType end
struct BlackHole     <: StellarType end

struct Star{T, tT <: StellarType}
    M::T
    L::T
    R::T
    stellar_type::tT
end
    
check_collision(body1::Star{T, tT <: MainSequence}, body2::Star{T, tT <: MainSequence}) = ...
check_collision(body1::Star{T, tT <: MainSequence}, body2::Star{T, tT <: BlackHole})    = ...
check_collision(body1::Star{T, tT <: BlackHole},    body2::Star{T, tT <: BlackHole})    = ...
```

## Unicode

![](figures/pn1.png){width=60%}


```{.julia}
r̄ = r̄₁ - r̄₂
v̄ = v̄₁ - v̄₂
r = norm(r̄) # r₁₂
r⁻¹ = 1/r
n = r̄*r⁻¹
v₁v₂ = dot(v̄₁, v̄₂) 
nv₁ = dot(n, v̄₁)
nv₂ = dot(n, v̄₂)
Gr⁻¹ = G*r⁻¹
Gr⁻² = Gr⁻¹*r⁻¹

# PN-1 acceleration
ai = @. n*(Gr⁻²*m₂)*(5*Gr⁻¹*m₁ + 4*Gr⁻¹*m₂ + 3/2*nv₂^2 - v₁² + 4*v₁v₂ - 2*v₂²) +
        (4*nv₁ - 3*nv₂)*v̄
```


