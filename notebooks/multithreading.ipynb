{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High-performance computing with Julia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we'll be looking at Julia's functionality for distributing work over multiple shared-memory workers (threads/cores). Julia also has two main packages for doing distributed-memory parallelism:\n",
    "\n",
    "- [Distributed.jl](https://docs.julialang.org/en/v1/stdlib/Distributed/) - this is a standard library that comes shipped with the language. \n",
    "- [MPI.jl](https://juliaparallel.org/MPI.jl/stable/) - a Julia wrapper for MPI.\n",
    "\n",
    "Additionally, Julia supports GPU programming via the [CUDA.jl](https://cuda.juliagpu.org/stable/) package. There is also ongoing work for supporting AMD, Intel, and Apple GPUs. You can read more about that [here](https://github.com/JuliaGPU/KernelAbstractions.jl)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multithreading in Julia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia comes packaged with a standard library called `Threads` for working with multiple shared-memory workers. However, before starting we need to make sure that Julia is started with more than one thread. To check how many Julia threads are currently running, call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Threads.nthreads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've just installed Julia without changing anything, this number will likely be one. There are multiple way to ensure that Julia starts with multiple threads.\n",
    "- Set the environment variable `JULIA_NUM_THREADS` to some number, for example to \"$(nproc)\" to use all the cores in your computer.\n",
    "- Start Julia with the `--threads` or `-t` option followed by the number of threads. I.e. `julia --threads 4`.\n",
    "- In VS Code, set the `\"julia.NumThreads\": NUMBER` option in `settings.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can readily check again how many threads we are running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Threads.nthreads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are threads?\n",
    "Threads are **execution units within a process** that can run simultaneously. While processes are separate, threads run in a **shared memory** space (heap).\n",
    "\n",
    "<!-- <img src=\"./imgs/what-are-threads.png\" width=500px> -->\n",
    "\n",
    "<br>\n",
    "<img src=\"../figures/stack_heap_threads.svg\" width=450px>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It is currently not (easily) possible to change the number of threads at runtime!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User threads vs default threads\n",
    "\n",
    "Technically, the Julia process is also spawning multiple threads already in \"single-threaded\" mode, like\n",
    "* a thread for unix signal listening\n",
    "* multiple OpenBLAS threads for BLAS/LAPACK operations\n",
    "* GC threads\n",
    "\n",
    "We call the threads that we can actually run computations on *user threads* or *Julia threads*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "BLAS.get_num_threads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where are my threads running?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ThreadPinning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hostname: \tCasparWB-API\n",
      "CPU(s): \t1 x 12th Gen Intel(R) Core(TM) i7-1260P\n",
      "CPU target: \talderlake\n",
      "Cores: \t\t8 (16 CPU-threads due to 2-way SMT)\n",
      "NUMA domains: \t1 (8 cores each)\n",
      "\n",
      "\u001b[32m\u001b[1mJulia threads: \t16\u001b[22m\u001b[39m\n",
      "\n",
      "\u001b[36m\u001b[1mCPU socket 1\u001b[22m\u001b[39m\n",
      "  \u001b[39m0,\u001b[95m\u001b[1m1\u001b[22m\u001b[39m, \u001b[31m\u001b[1m2\u001b[22m\u001b[39m,\u001b[95m\u001b[1m3\u001b[22m\u001b[39m, \u001b[33m\u001b[1m4\u001b[22m\u001b[39m,\u001b[95m\u001b[1m5\u001b[22m\u001b[39m, \u001b[33m\u001b[1m6\u001b[22m\u001b[39m,\u001b[95m\u001b[1m7\u001b[22m\u001b[39m, \u001b[33m\u001b[1m8\u001b[22m\u001b[39m,\u001b[90m9\u001b[39m, \u001b[33m\u001b[1m10\u001b[22m\u001b[39m,\u001b[95m\u001b[1m11\u001b[22m\u001b[39m, \u001b[33m\u001b[1m12\u001b[22m\u001b[39m,\u001b[95m\u001b[1m13\u001b[22m\u001b[39m, \u001b[33m\u001b[1m14\u001b[22m\u001b[39m,\u001b[95m\u001b[1m15\u001b[22m\u001b[39m\n",
      "\n",
      "\n",
      "\u001b[33m\u001b[1m#\u001b[22m\u001b[39m = Julia thread, \u001b[95m\u001b[1m#\u001b[22m\u001b[39m = Julia thread on HT, \u001b[31m\u001b[1m#\u001b[22m\u001b[39m = >1 Julia thread\n",
      "\n",
      "\u001b[90m(Mapping:\u001b[39m\u001b[90m 1 => 4,\u001b[39m\u001b[90m 2 => 2,\u001b[39m\u001b[90m 3 => 14,\u001b[39m\u001b[90m 4 => 5,\u001b[39m\u001b[90m 5 => 1,\u001b[39m\u001b[90m ...\u001b[39m)\n"
     ]
    }
   ],
   "source": [
    "threadinfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task-based multithreading\n",
    "\n",
    "In traditional HPC, one typically cares about threads directly. Using e.g. OpenMP, one essentially tells each thread what to do.\n",
    "\n",
    "Conceptually, Julia takes a different approach and implements **task-based** multithreading. In this paradigm, a task - e.g. a computational piece of a code - is marked for **parallel** execution on **any** of the available Julia threads. Julia's **dynamic scheduler** will automatically put the task on one of the threads and trigger the execution of the task on said thread.\n",
    "\n",
    "<br>\n",
    "<!-- <img src=\"imgs/task-based-parallelism.png\" width=768px> -->\n",
    "<img src=\"../figures/tasks_threads_cores.svg\" width=650px>\n",
    "</br>\n",
    "\n",
    "Generally speaking, the user should **think about tasks and not threads**.\n",
    "* The scheduler is controlling on which thread a task will eventually run.\n",
    "* It might even dynamically [migrate tasks](https://docs.julialang.org/en/v1/manual/multi-threading/#man-task-migration) between threads.\n",
    "\n",
    "**Advantages:**\n",
    "* high-level abstraction\n",
    "* nestability / composability (especially important for libraries)\n",
    "\n",
    "**Disadvantages:**\n",
    "* scheduling overhead\n",
    "* uncertain and potentially suboptimal task → thread assignment\n",
    "  * **can get in the way when performance engineering** because\n",
    "    * scheduler has limited information (e.g. about the system topology)\n",
    "    * profiling tools often don't know anything about tasks but monitor threads (or even CPU-cores) instead (e.g. LIKWID)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, Julia waits for commands to finish (\"**blocking**\") and runs everything sequentially.\n",
    "\n",
    "**Tasks** are a feature that allows (parts of) computations to be scheduled (suspended and resumed) in a flexible manner to implement **concurrency** and **parallelism**.\n",
    "\n",
    "* Concurrency\n",
    "    * Dealing with lots of things *in a time period* (\"multi-tasking\").\n",
    "    * Can be used on a single thread.\n",
    "* Parallelism\n",
    "    * Doing lots of things *at the same instant*.\n",
    "    * Needs multiple threads (or processes).\n",
    "\n",
    "Example (concurrency): **asynchronous I/O** like\n",
    "  * **multiple user input** (Why not already process some of the input?)\n",
    "  * **data dumping to disk** (Maybe it's possible to continue a calculation?)\n",
    " \n",
    "Example (parallelism): **multithreading, distributed computing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spawning parallel tasks: `Threads.@spawn`\n",
    "`Threads.@spawn` spawns a task to be run on any Julia thread. Specifically, it creates a `Task` and schedules it for execution on an available Julia thread (we don't control which one!).\n",
    "\n",
    "Note that `Threads.@spawn` is **asynchronous** and **non-blocking**, that is, it doesn't wait for the task to actually run but immediately returns a `Task`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Base.Threads # afterwards we can just write @spawn instead of Threads.@spawn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Task (done) @0x00007f78d5c26d60"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@spawn 3+3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fetch the result of a task with `fetch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = @spawn 3+3\n",
    "fetch(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While `@spawn` returns right away, `fetch` is **blocking** as it has to wait for the task to actually finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000393 seconds (1.25 k allocations: 62.406 KiB)\n",
      "  2.930254 seconds (104 allocations: 4.188 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@time t = @spawn begin\n",
    "    sleep(3)\n",
    "    return 3+3\n",
    "end\n",
    "@time fetch(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the macro `@sync` to synchronize all encompassed asynchronous operations (`@spawn`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3.008581 seconds (11.64 k allocations: 605.484 KiB, 0.22% compilation time)\n",
      "  0.000009 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@time @sync t = @spawn begin\n",
    "    sleep(3)\n",
    "    return 3+3\n",
    "end\n",
    "@time fetch(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: multithreaded `map`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tmap`: *threaded map*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tmap (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function tmap(fn, itr)\n",
    "    tasks = map(i -> @spawn(fn(i)), itr)  # for each i ∈ itr, spawn a task to compute fn(i)\n",
    "    return fetch.(tasks)                  # fetch and return all the results\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = [rand(200,200) for i in 1:8];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Vector{Vector{Float64}}:\n",
       " [100.20838520782826, 8.074398919833639, 7.9198275218987995, 7.747850965071262, 7.637500376625816, 7.610284365656103, 7.486828646174716, 7.405870161493915, 7.359989378697254, 7.275497028052682  …  0.27572533232943347, 0.24370274844701004, 0.20832024053757534, 0.18645182730288187, 0.16180357010162813, 0.14113474037036663, 0.09942087943232351, 0.07009203025062351, 0.053065402524928376, 0.011392981709151801]\n",
       " [100.11385819555302, 8.180389220880404, 7.908630658700188, 7.726741914252684, 7.687339405827408, 7.496328331426023, 7.410523868186568, 7.37484661285418, 7.3089415863336304, 7.273974314097562  …  0.29951460156031257, 0.2801283461701338, 0.24302044310150994, 0.22874156070567966, 0.19938947628434303, 0.1670554200328792, 0.11083854291073707, 0.05382323932997336, 0.040080836350062085, 0.002093292409368463]\n",
       " [100.22917249696874, 8.0338897377666, 7.832750252510585, 7.792933293413332, 7.74572093071225, 7.607049665751441, 7.440680341270445, 7.332727562141124, 7.3008161818901, 7.269041824332642  …  0.3079059699326548, 0.2701760189191776, 0.22166812329345698, 0.1894044798614614, 0.1846677469260929, 0.14375863841967496, 0.09531205273713454, 0.06078938526906995, 0.05666906076425464, 0.02384946446738327]\n",
       " [100.09970194100953, 7.92768645863747, 7.744143725278405, 7.701910594051981, 7.6654300037081375, 7.580948706585103, 7.50260608169607, 7.435430221317522, 7.338555071384187, 7.276395557731218  …  0.27656466410226344, 0.27192492251743733, 0.2587875188700486, 0.23497575382511784, 0.1791069426597724, 0.11750993388889419, 0.10291209080363577, 0.06625304373716888, 0.04982329699963371, 0.003998662911856366]\n",
       " [100.30266993624477, 8.088482461824539, 7.7849245911042635, 7.758620092425389, 7.621820392453219, 7.542383880380979, 7.44415835088892, 7.364355232120647, 7.309318431595685, 7.271809108854674  …  0.25638412862828913, 0.23857123386721749, 0.2114634574154899, 0.18653613597707314, 0.1264056976115464, 0.09723417236745716, 0.06768047964276479, 0.040469207142354524, 0.01184659458122073, 0.01029685360058059]\n",
       " [100.4084673372084, 7.989526173099858, 7.817744447542591, 7.7280504049802685, 7.609426628065541, 7.531216957194956, 7.4518255768713075, 7.319873886362572, 7.2681600804559645, 7.247896329842636  …  0.29146688545691435, 0.2782114736459764, 0.24124997893157213, 0.19850156600153815, 0.1752058330577013, 0.15904045491375166, 0.11455359158408246, 0.05610563769276191, 0.04170334379264037, 0.020337750834682554]\n",
       " [100.61723358442772, 8.117048715292478, 7.995052405126408, 7.8201365331923745, 7.678289240006457, 7.56992217786379, 7.450113347125828, 7.433531857124923, 7.283967891019347, 7.267600797553062  …  0.31325363658771854, 0.2804939822601949, 0.2391278544968002, 0.23242206005478977, 0.18951043596953046, 0.17501739347851877, 0.11737548532894694, 0.09332882608657583, 0.029259944969272686, 0.011210176062952108]\n",
       " [99.66895387884523, 7.960632678766488, 7.884985471395318, 7.7649095769826095, 7.656782199444693, 7.599624189113684, 7.521470814981164, 7.335754650824105, 7.3232987984193585, 7.26403268863684  …  0.33936464596259686, 0.26812469776647313, 0.241171771243057, 0.20585355977850314, 0.1684826802896077, 0.15217958284798783, 0.09864564027470883, 0.0502278450107729, 0.02741112088557612, 0.011422434120189293]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmap(svdvals, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3.945 ms (155 allocations: 3.38 MiB)\n",
      "  17.142 ms (106 allocations: 3.37 MiB)\n"
     ]
    }
   ],
   "source": [
    "@btime tmap($svdvals, $M) samples=10 evals=3;\n",
    "@btime map($svdvals, $M) samples=10 evals=3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**performance issue**:\n",
    "\n",
    "* Using Julia multithreading + BLAS multithreading\n",
    "    - CPU cores may be *overscribed*, e.g. 256 total threads on 128 CPU cores! (red bars in `htop`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you use BLAS, it is important to carefully consider and configure the [interplay between Julia threads and BLAS threads](https://carstenbauer.github.io/ThreadPinning.jl/stable/explanations/blas/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLAS.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4.734 ms (155 allocations: 3.38 MiB)\n",
      "  16.049 ms (106 allocations: 3.37 MiB)\n"
     ]
    }
   ],
   "source": [
    "@btime tmap($svdvals, $M) samples=10 evals=3;\n",
    "@btime map($svdvals, $M) samples=10 evals=3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: multithreading for-loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ThreadPinning.Utility: taskid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 11488916986724442474 is running iteration 1 on thread 2\n",
      "Task 15234522458667997043 is running iteration 26 on thread 5\n",
      "Task 957369398481928481 is running iteration 18 on thread 15\n",
      "Task 3284671388240129601 is running iteration 24 on thread 1\n",
      "Task 6811353691080217303 is running iteration 30 on thread 11\n",
      "Task 7405514637394808702 is running iteration 29 on thread 11\n",
      "Task 2403952435711093788 is running iteration 15 on thread 6\n",
      "Task 14155726864905622120 is running iteration 28 on thread 5\n",
      "Task 2187117897820264066 is running iteration 11 on thread 5\n",
      "Task 2063126083167385598 is running iteration 16 on thread 1\n",
      "Task 6368343915477012251 is running iteration 6 on thread 7\n",
      "Task 8779815644241969064 is running iteration 9 on thread 3\n",
      "Task 6401274383233523539 is running iteration 3 on thread 15\n",
      "Task 12220232873917988113 is running iteration 31 on thread 13\n",
      "Task 8556070160371430310 is running iteration 2 on thread 13\n",
      "Task 17417801917760207650 is running iteration 25 on thread 16\n",
      "Task 10481352488650838361 is running iteration 27 on thread 16\n",
      "Task 4915018922051311536 is running iteration 17 on thread 1\n",
      "Task 13878637706159516372 is running iteration 5 on thread 9\n",
      "Task 12427686974951127523 is running iteration 20 on thread 15\n",
      "Task 9943988327323939958 is running iteration 23 on thread 16\n",
      "Task 10536772225518385931 is running iteration 8 on thread 8\n",
      "Task 7928786662477724821 is running iteration 14 on thread 10\n",
      "Task 7600666058004619106 is running iteration 21 on thread 2\n",
      "Task 12785774314232295140 is running iteration 32 on thread 11\n",
      "Task 17491019180919387919 is running iteration 12 on thread 12\n",
      "Task 14395742624853347402 is running iteration 10 on thread 16\n",
      "Task 9476059654615815574 is running iteration 22 on thread 16\n",
      "Task 7447250725915697721 is running iteration 19 on thread 2\n",
      "Task 6698950389040161975 is running iteration 4 on thread 11\n",
      "Task 1201826150966402335 is running iteration 7 on thread 14\n",
      "Task 7687644943994953458 is running iteration 13 on thread 4\n"
     ]
    }
   ],
   "source": [
    "@sync for i in 1:2*nthreads()\n",
    "    @spawn println(\"Task \", taskid(), \" is running iteration \", i, \" on thread \", threadid())\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `@threads`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Splits up the iteration space into `nthreads()` contiguous chunks**\n",
    "* Creates a task for each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 3265126592589086464 is running iteration 1 on thread 2\n",
      "Task 1843399858258310311 is running iteration 21 on thread 10\n",
      "Task 3265126592589086464 is running iteration 2 on thread 2\n",
      "Task 15414827125662656820 is running iteration 25 on thread 16\n",
      "Task 4639816724120330272 is running iteration 11 on thread 8\n",
      "Task 9070916526061227709 is running iteration 23 on thread 7\n",
      "Task 2446670846823866856 is running iteration 13 on thread 13\n",
      "Task 4639816724120330272 is running iteration 12 on thread 8\n",
      "Task 12709182576872726629 is running iteration 29 on thread 1\n",
      "Task 2216687187093315125 is running iteration 15 on thread 9\n",
      "Task 2446670846823866856 is running iteration 14 on thread 13\n",
      "Task 9630774442592466691 is running iteration 5 on thread 14\n",
      "Task 1843399858258310311 is running iteration 22 on thread 10\n",
      "Task 15414827125662656820 is running iteration 26 on thread 16\n",
      "Task 13489389001739313653 is running iteration 9 on thread 11\n",
      "Task 13626781883161134767 is running iteration 3 on thread 15\n",
      "Task 9630774442592466691 is running iteration 6 on thread 2\n",
      "Task 12709182576872726629 is running iteration 30 on thread 6\n",
      "Task 3334582222457047030 is running iteration 17 on thread 12\n",
      "Task 5783953857203486414 is running iteration 19 on thread 3\n",
      "Task 14750043052814518229 is running iteration 27 on thread 6\n",
      "Task 13626781883161134767 is running iteration 4 on thread 15\n",
      "Task 3334582222457047030 is running iteration 18 on thread 12\n",
      "Task 13489389001739313653 is running iteration 10 on thread 11\n",
      "Task 5783953857203486414 is running iteration 20 on thread 3\n",
      "Task 14021037182215336077 is running iteration 7 on thread 4\n",
      "Task 14750043052814518229 is running iteration 28 on thread 5\n",
      "Task 2216687187093315125 is running iteration 16 on thread 10\n",
      "Task 14021037182215336077 is running iteration 8 on thread 4\n",
      "Task 9070916526061227709 is running iteration 24 on thread 7\n",
      "Task 4531743797735628678 is running iteration 31 on thread 5\n",
      "Task 4531743797735628678 is running iteration 32 on thread 14\n"
     ]
    }
   ],
   "source": [
    "# creates nthreads() many tasks\n",
    "\n",
    "@threads for i in 1:2*nthreads()\n",
    "    println(\"Task \", taskid(), \" is running iteration \", i, \" on thread \", threadid())\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nestability / Composability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Recursive Fibonacci series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ F(n) = F(n-1) + F(n-2), \\qquad F(1) = F(2) = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can nest `@spawn` calls freely!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fib (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function fib(n)\n",
    "    n < 2 && return n\n",
    "    t = @spawn fib(n-2)\n",
    "    return fib(n-1) + fetch(t)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6765"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fib(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note: Algorithmically, this is a highly inefficient implementation of the Fibonacci series, of course!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multithreading: Things to be aware of"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructive example: parallel summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rand(1_000_000 * Threads.nthreads());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sum_threads_naive (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function sum_threads_naive(data)\n",
    "    s = zero(eltype(data))\n",
    "    @threads for x in eachindex(data)\n",
    "        s += x\n",
    "    end\n",
    "    return s\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum(data) = 8.001388345539851e6\n",
      "sum_threads_naive(data) = 1.3508063908667e13\n",
      "sum_threads_naive(data) = 7.500400619616e12\n"
     ]
    }
   ],
   "source": [
    "@show sum(data);\n",
    "@show sum_threads_naive(data);\n",
    "@show sum_threads_naive(data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wrong** result! Even worse, it's **non-deterministic** and different every time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a [race condition](https://en.wikipedia.org/wiki/Race_condition) which typically appear when multiple tasks are modifying a shared value simultaneously.\n",
    "\n",
    "→ **Don't modify shared \"global\" state!**\n",
    "\n",
    "Sometimes things can be more subtle. Examples: random number generation, `Dict`. Note that not all of Julia and its packages in the ecosystem are thread-safe! In general, it is safer to assume that they're not unless documented/proven otherwise. (`rand()` is thread-safe, `Dict` isn't!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools for multi-threading\n",
    "\n",
    "* [OhMyThreads.jl](https://github.com/JuliaFolds2/OhMyThreads.jl): Simple tools for basic multithreading.\n",
    "* [ThreadsX.jl](https://github.com/JuliaFolds2/ThreadsX.jl): Parallelized Base functions\n",
    "* [Tullio.jl](https://github.com/mcabbott/Tullio.jl): Tullio is a very flexible einsum macro ([Einstein notation](https://en.wikipedia.org/wiki/Einstein_notation))\n",
    "* [(LoopVectorization.jl)](https://github.com/JuliaSIMD/LoopVectorization.jl): Macro(s) for vectorizing loops.\n",
    "* [(FLoops.jl)](https://github.com/JuliaFolds/FLoops.jl): Fast sequential, threaded, and distributed for-loops for Julia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-do the exercise `Counting nucleotides` from the `basics.ipynb` notebook by implementing a multithreaded version. Compare the performance with a single-threaded. Try generating your own strings with different lengths and compare the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.3",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
